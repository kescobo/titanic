## Kaggle Titanic Analysis in Julia

Practicing using julia for ML analysis - taking inspiration from [Ajinkya Kale](http://ajkl.github.io/2015/08/10/Titanic-with-Julia/)

Test and training data [downloaded from kaggle](https://www.kaggle.com/c/titanic/data) and put into `data/` folder. Let's read it into julia:

```julia
using DataFrames

train = readtable("data/train.csv")
tst = readtable("data/test.csv")

describe(train)
```

In the training set, people that survived get a `1` in the `:Survived` column, so we can see from the data summary that ~38.4% of passengers survived (the mean of that column). Or we can look at it directly:

```julia
proportionmap(train[:Survived])
```

... or to get total numbers

```julia
countmap(train[:Survived])
```

All the tutorials I've seen start with looking gender as the first explanatory variable to predict who survives, but I'm going to show my strong liberal bias and look first at socioeconomic status. There are a couple of ways we could do this - there is a column for passenger class (1st, 2nd or 3rd - `train[:pclass]`), and it says right there in the [data description](https://www.kaggle.com/c/titanic/data) that

>Pclass is a proxy for socio-economic status (SES)
 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower."

But just for fun (and maybe a little be to be contrarian), I'm going to instead look at the cost of the fare, which is a continuous rather than a categorical variable. My prediction is that people that paid more for their fare are more likely to survive. looking back at the output from `describe()`, we can see that the mean fare for all passengers in the training set is about \$32. Let's look what happens if we look at only the survivors.

```julia
using Plots
pyplot()

survived = train[train[:Survived] .== 1, :]
died = train[train[:Survived] .== 0, :]

describe(survived[:Fare])
describe(died[:Fare])
```

That's quite a stark difference! We could also separate the fares based on quartiles (again, look back at the initial call to `describe()`) and plot it.

The syntax below is a way of subsetting the dataframe - if you pass a vector of `true` and `false` that's the same length as a column in the df, it will only grab the rows of the dataframe that correspond to `true`. Say I want all rows, where the fare paid is less than \$10 - eg, `train[:Fare] .< 10`. The `.<` applies the inequality for the whole length of the vector and returns a vector of boolean values (techincally it's a `BitArray`)

```julia
[1,2,3] .< 3
```

This means I can just subset a dataframe by passing the inequality into the subset syntax - instead of `train[1:4]` (which would give me rows 1 to 4), I can do `train[train[:Fare] < 10, :]`. The second argument (`, :`) tells it to return all columns, though I can also grab a subset. eg:

```julia
train[:fare_qtl] = 1 # makes a new column, all = 1
train[7.9 .< train[:Fare] .<= 14.45, :fare_qtl] = 2
train[14.45 .< train[:Fare] .<= 32.2, :fare_qtl] = 3
train[32.2 .< train[:Fare], :fare_qtl] = 4

fqtl = by(train, :fare_qtl, df -> mean(df[:Survived])) # makes a new 4x2 dataframe

bar(fqtl[:fare_qtl], fqtl[:x1], xlabel="Fare Quartile", ylabel="Fraction Survived", legend=false)
```

Well. Shocker.

OK, let's go ahead and bring gender into this.

```julia
fqtl = by(train, [:fare_qtl, :Sex], df -> mean(df[:Survived]))
xs = [[1,2,3,4], [1,2,3,4]]
ys = [fqtl[fqtl[:Sex] .== "female", :x1], fqtl[fqtl[:Sex] .== "male", :x1]]
bar(xs, ys, color=[:purple :orange], xlabel="Fare Quartile", ylabel="Fraction Survived", label=["female" "male"])
```

So that's interesting, except for the highest fares, the difference in survival between the different groups seems to be driven entirely by the men. And poor men sure were screwed...

## Let the computer do the work.

But why try to guess what matters when we've got machine learning? In [the tutorial](http://ajkl.github.io/2015/08/10/Titanic-with-Julia/) I'm looking at, they take variables with `NA` values like the port of embarkation and age of the passenger and set them to the most common value and the median respectively. I don't know if this is common practice, and I can understand the reasoning, but it seems odd to me. Instead, I'm just going to eliminate those data points.

```julia
train = train[!isna(train[:Embarked]) & !isna(train[:Age]), :]
```
Again, the `!isna()` function returns a `BitArray`, which grabs a subset, and the `&` operator is a bitwise and, so each row has to fulfil both conditions.

The point of this whole exercise (for me at least) is to get some practise with some of julia's machine learning capabilities. Let's try `DecisionTrees`:

```julia
using DecisionTree
features = Array(train[:, [:Age, :Fare, :Sex, :SibSp, :Pclass, :Parch]])
labels = Array(train[:Survived])

stump = build_stump(labels, features)
print_tree(stump)
```

OK, fine - I guess it does make the most sense to start with gender. Let's build out the model:

```julia
model = build_tree(labels, features)
model = prune_tree(model, .7)

purities = linspace(0.1, 1.0, 5)
accuracies = zeros(length(purities))

for i in 1:length(purities)
    accuracies[i] = mean(nfoldCV_tree(labels, features, purities[i], 5))
end

plot(purities, accuracies, ylabel="Accuracy", xlabel="Threshold", marker="circle")
```

Based on the explanation in the blog post I linked to, the `nfoldCV_tree()` function takes the training set, and checks how pruning at different thresholds (in this case we give it 5 thresholds to test between 0.1 and 1) affects the accuracy of the prediction by randomly subsetting the dataset into training and testing sets. The 2x2 matricies being returned are [confusion matricies](https://en.wikipedia.org/wiki/Confusion_matrix), which show how the predictions compare with the reality.

## Making a prediction
The competition on kaggle asks for a csv containing passenger IDs and a prediction of survival from the test set. The tutorial doesn't mention how to go from training the model to using it, but i found some more info in [the docs]().

```julia
model = build_tree(labels, features) # rebuild the model
model = prune_tree(model, 0.6) # using 0.6 based on nfoldCV_tree
```
When I tried to run `testfeatures = Array(tst[:, [:Age, :Fare, :Sex, :SibSp, :Pclass, :Parch]])`, I got an error. Hmm... this is maybe why we have to artifically change the NA's to the median or most frequent values for a column. Let's check which columns have NAs.

```julia
for name in names(tst)
    if length(tst[name]) > length(dropna(tst[name]))
        println(name)
    end
end
```
We don't care about Cabin (these should all be unique more or less), but we can fix the other two. The following code grabs the rows were `:Age` (or `:Fare`) is NA, and then sets the value of `:Age` (or `:Fare`) in each of those cells to the mean of that column.

```julia
tst[isna(tst[:Age]), :Age] = mean(dropna(tst[:Age]))
tst[isna(tst[:Fare]), :Fare] = mean(dropna(tst[:Fare]))
```

OK, let's try applying our model again.

```julia
testfeatures = Array(tst[:, [:Age, :Fare, :Sex, :SibSp, :Pclass, :Parch]])

predictions = apply_tree(model, testfeatures)
```
OK, we've got our predictions, let's format them for Kaggle and see how I did.

```julia
df = DataFrame(PassengerId = tst[:PassengerId], Survived = predictions)
writetable("data/dt_predictions.csv", df)
```

I scored `0.71770`... ahh well, not bad for a first go I suppose.
